{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n",
    "*Existing* -- part 1; progress reports 1 & 2\n",
    "\n",
    "**[View the data parsing script!](data_parsing_script.py)**\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Catching issues](#catching-issues)\n",
    "- [What the parser is doing](#what-the-parser-is-doing)\n",
    "- [Fixing more parsing issues](#fixing-more-parsing-issues)\n",
    "- [Vowel changes](#vowel-changes)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "My goal with the data parsing is to fit each \"branch\" and sound change rule in the data into a predefined data format.\n",
    "\n",
    "How should I go about doing this? There are a few options. I want my end result to allow me to have a kind of connected graph between individual sounds, and I want to be able to see what rules and language branches the connections come from.\n",
    "\n",
    "Because of this, I think I want to have two different \"collections\" of objects:\n",
    "\n",
    "1. Rules\n",
    "2. Branches\n",
    "\n",
    "I'm going to opt to output these as JSON files, since I much prefer that format over XML for readability. I may also pickle them so that I can import them more easily when doing visualizations.\n",
    "\n",
    "Each object type will be its own class, so I can have a set of predefined fields on each.\n",
    "\n",
    "## Catching issues\n",
    "\n",
    "My first version of the data parsing script (2/21/23) worked somewhat well, but there were some that were parsed incorrectly. Here's a rundown of what was still not working:\n",
    "\n",
    "1. Sound changes with multiple correlated rules -- e.g. `z zː → j dʒː` -- were being parsed as single rules.\n",
    "2. Sounds grouped together -- e.g. in `{s3,ʒ} → ʃ / #_` -- were being parsed as one sound.\n",
    "3. Sounds like `S[+ voiced]` were being parsed as two separate sounds -- `S[+` and `voiced]` -- because I was naively splitting at all spaces.\n",
    "4. Some extra text was not being filtered out correctly, such as the quotation in `ɨ u → e {i,e} “(all */u/ affected, but conditions for when it became /i/ or /e/ are not known)”`.\n",
    "5. Rules like `rdʒ → {rdʒ,rdz(→ rz)}` that had optional steps were not parsed correctly at all.\n",
    "6. Optional modifiers to sounds, like `ts(ʼ)`, were parsed as one rule rather than two (`ts`, `tsʼ`.)\n",
    "\n",
    "**Have no idea what this means?** I don't blame you. I go into more detail in the \"Parsing sound changes\" section below.\n",
    "\n",
    "There were almost certainly other issues, but these were the ones I noticed. Some of these were going to be harder to fix than others.\n",
    "\n",
    "There were some cases where making the parser handle a certain situation was not worth it, as the number of rules that would be handled by that was negligible, so I manually modified those rules so they would be parsed correctly. I also did this in cases where there was plain text like \"occasionally\". I made a new file `sid-tidy-with-edits.html` so the unedited version would still be accessible.\n",
    "\n",
    "There are also some rules where multiple end results are listed due to the source's author \"hedging\", so I edited those manually to consider both end results as their own rules.\n",
    "\n",
    "I also decided to make it so that anything within backticks is ignored when parsing but included in the 'original text' field of the rule. This lets me manually handle rules like `r → *L (some sort of lateral?) / occasionally` with extra stuff that I want to ignore, without losing that information.\n",
    "\n",
    "Another oddity is this fun one: `s → c& _ (the paper doesn’t explain what this represents)`. How am I supposed to parse this??? Who knows. I'm going to just manually add an environment separator and assume it's supposed to mean \"in any environment.\"\n",
    "\n",
    "I also realized there were some cases where there were simply typos in the data, such as `ŋ → {∅,n} #_ else` (which is missing the environment separator before `#_`.) I manually fixed those.\n",
    "\n",
    "Fortljus Ryggrad's *[Corrections, Clarifications, and Uncertainties of Index Diachronica](https://drive.google.com/file/d/1veWbeZhXUZjUtGZZezyvCvF6BA103wS8/view?usp=sharing)* helped me resolve some of the oddities I ran into when parsing as well.\n",
    "\n",
    "As I fixed some of the broken cases (+ others as I found them), I included them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', [], 'j'), ('zː', [], 'dʒː')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_parsing_script as dps\n",
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('z zː → j dʒː')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', [], '[+ voice]')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('S → [+ voice]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j', [], 'i'), ('w', [], 'u')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('— j w → i u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V[- high - long]', [], '∅')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('V[- high - long] → ∅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ew', ['øj'], 'yj'), ('ew', [], 'yj')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('ew (→ øj) → yj', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<data_parsing_script.Rule at 0x7f258c791d80>,\n",
       " <data_parsing_script.Rule at 0x7f258c791c00>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dps.parse_sound_change('ew (→ øj) → yj', '', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ʒ', [], 'ʃ'), ('s3', [], 'ʃ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('{s3,ʒ} → ʃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tʃʷʼ', [], 'fʼ'),\n",
       " ('tɕʼ', [], 'tsʼ'),\n",
       " ('dʒʷ', [], 'v'),\n",
       " ('dʑ', [], 'dz'),\n",
       " ('tʃʷ', [], 'fʼ'),\n",
       " ('tɕ', [], 'tsʼ'),\n",
       " ('tʃʷʼ', [], 'f'),\n",
       " ('tɕʼ', [], 'ts'),\n",
       " ('tʃʷ', [], 'f'),\n",
       " ('tɕ', [], 'ts')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('tʃʷ(ʼ) tɕ(ʼ) dʒʷ dʑ → f(ʼ) ts(ʼ) v dz', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rdʒ', [], 'rdz'), ('rdʒ', [], 'rdʒ')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('rdʒ → {rdʒ,rdz}', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', [], 't'), ('ɡ', [], 'k')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('d ɡ → t k (may have been part of a more sweeping merger; Firespeaker calls it “lenis-fortis”)', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', [], '*L')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('r → *L `(some sort of lateral?)` / occasionally', '', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('æi', [], 'eː'),\n",
       " ('ei', [], 'eː'),\n",
       " ('ai', [], 'aː'),\n",
       " ('au', [], 'oː'),\n",
       " ('wi', [], 'weː'),\n",
       " ('wɪ', [], 'weː'),\n",
       " ('wu', [], 'woː'),\n",
       " ('wV', [], 'wVː'),\n",
       " ('i', [], 'eː'),\n",
       " ('u', [], 'oː'),\n",
       " ('V', [], 'Vː')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('{æ,e}i ai au w{ɪ,i} wu wV i u V → eː aː oː weː woː wVː eː oː Vː')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lːʀ', [], 'lː'), ('nːʀ', [], 'nː'), ('lʀ', [], 'lː'), ('nʀ', [], 'nː')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('l(ː)ʀ n(ː)ʀ → lː nː / ”Vː_ (or all V_ ?)', '', '', '')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...AND IT ALL PARSES! Only took like 4 hours of running it over and over and fixing any errors that were hit!!\n",
    "\n",
    "However, as of now, there is still some data parsing stuff still to take care of:\n",
    "\n",
    "1. Rules with multiple optional things that are the same (e.g. `(C)(C)`) are only parsed as being all-or-nothing (one `(C)` is not possible). After fixing this, rules where `(:)` on both sides of the rule mean \"long becomes long, short becomes short\" still need to be handled correctly (e.g. `N(ː) k k(ː) N(ː)ɡ ɡ(ː) ɣ → ɲc(ː) c(ː) ɲɟ(ː) ɟ(ː) ʝ / _{i,j} `)\n",
    "2. Nested curly brackets are not handled correctly. (`{e,w{æ,i}}` is parsed as `['{e,wæ', '{e,wi}']`)\n",
    "3. I need to through everything and look for any more obvious errors. (Maybe sort individual sounds by length to find outliers?)\n",
    "\n",
    "I'm happy with the current state of things for the first progress report, though.\n",
    "\n",
    "## What the parser is doing\n",
    "\n",
    "1. It loops through each `<section>` tag on the page, each of which is a branch from a parent language to a daughter language (e.g. Proto-Germanic to Proto-Norse), and parses information about the branch. This is pretty simple.\n",
    "2. It then loops through each sound change listed in the section and parses THAT. This is where it gets messy.\n",
    "\n",
    "<a id=\"parsing-sound-changes\"></a>\n",
    "\n",
    "### Parsing sound changes\n",
    "\n",
    "Sound changes in the *Index* are in a (relatively...) standard format. The 'from' and 'to' sounds are separated by an arrow (with some intermediate steps sometimes), while the environment of the sound change is specified after a forward slash. The specifics of how environments are written aren't necessary to know for this, since I mostly just care about the sounds themselves.\n",
    "\n",
    "When parsing a sound change, first, any text contained in backticks is removed from the sound change text (as noted above), as is any `(?)`. Then, the environment is split off from the rest of the rule. (Often, rules are followed by some text in parentheses or double-quotes, so I include that in the environment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(sporadic)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "rule_string = 'd j → r ɭ (sporadic)'\n",
    "\n",
    "env_split = rule_string.split(\" / \", 1)\n",
    "\n",
    "environment = ''\n",
    "\n",
    "if len(env_split) > 1:\n",
    "    environment = env_split[1]\n",
    "else:\n",
    "    # If no environment, but rule ends with some text in parentheses or quotes, consider that the environment\n",
    "    parens_match = re.search(r'(.+) (\\(.+\\)|“.+”)$', rule_string)\n",
    "    if parens_match:\n",
    "        env_split[0] = parens_match.group(1)\n",
    "        environment = parens_match.group(2)\n",
    "\n",
    "environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the steps are split up and every sound is separated out. This is because I want single sound changes, like `a → o`, and a sound change like `a e → o i` is equivalent to `a → o` and `e → i` separately.\n",
    "\n",
    "This is the first place where things get pretty complex. First, I need to handle any 'optionals', the name I've given to stuff in parentheses in rules like `a(i) → ey`, which is equivalent to `a → ey` and `ai → ey` separately. Because there can be multiple in a single rule, I need to have every possible combination accounted for. I used `itertools`' `combinations()` function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai {e,w{æ,i}} {we,ei} wɪ → ey ø y ʏ\n",
      "a {e,w{æ,i}} {we,ei} wɪ → ey ø y ʏ\n",
      "ai {e,w{æ,i}} {we,ei} ɪ → ey ø y ʏ\n",
      "a {e,w{æ,i}} {we,ei} ɪ → ey ø y ʏ\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "rule_string = 'a(i) {e,w{æ,i}} {we,ei} (w)ɪ → ey ø y ʏ'\n",
    "\n",
    "optionals = re.findall(r'(\\(.*?\\))', rule_string)\n",
    "if (optionals):\n",
    "    combinations = list(itertools.chain.from_iterable(itertools.combinations(optionals, l) for l in range(len(optionals) + 1)))\n",
    "    for combo in combinations:\n",
    "        combo_string = rule_string\n",
    "        for to_replace in combo:\n",
    "            combo_string = combo_string.replace(to_replace, '')\n",
    "        combo_string = combo_string.replace('(','').replace(')','')\n",
    "        print(combo_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, each of those are run through a `parse_rule_steps` function, which does a lot, including:\n",
    "\n",
    "1. Removing extraneous symbols\n",
    "2. Splitting the rules into steps\n",
    "3. Splitting the steps into each sound\n",
    "4. Making sure the number of sounds at each step are the same (so they can be correlated correctly)\n",
    "5. Splitting bracketed sounds into individual sounds, and generating rules for each combination of those individual sounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CaNs', 'CeNs', 'CiNs']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_brackets(sound: str) -> list[str]:\n",
    "    \"\"\"Handles bracketed sounds\"\"\"\n",
    "    sounds: list[str] = []\n",
    "    if bracket_matches := re.match(r'^(\\D+)?\\{(.*)\\}(\\D+)?$', sound):\n",
    "        # print(f'bracketed sound {sound}')\n",
    "        prefix = str(bracket_matches.group(1) or '')\n",
    "        split = bracket_matches.group(2).split(',')\n",
    "        suffix = str(bracket_matches.group(3) or '')\n",
    "        for sound in split:\n",
    "            sounds.append(prefix + sound + suffix)\n",
    "    else:\n",
    "        sounds.append(sound)\n",
    "    return sounds\n",
    "\n",
    "handle_brackets('C{a,e,i}Ns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, everything is output to JSON and pickle files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16496 rules in 702 branches\n",
      "{\n",
      "    \"branch_id\": \"Hassāniyya-Arabic\",\n",
      "    \"branch_index\": \"6.2.2.1.10\",\n",
      "    \"environment\": \"C_{C,#} (except for the feminine marker)\",\n",
      "    \"from_sound\": \"V[-long]\",\n",
      "    \"id\": \"Hassāniyya-Arabic-V-long\",\n",
      "    \"intermediate_steps\": [],\n",
      "    \"original_text\": \"V[-long] → ∅ / C_{C,#} (except for the feminine marker)\",\n",
      "    \"to_sound\": \"∅\"\n",
      "}\n",
      "{\n",
      "    \"branch_id\": \"Ahchypsy-Abkhaz\",\n",
      "    \"branch_index\": \"12.1.3\",\n",
      "    \"environment\": \"\",\n",
      "    \"from_sound\": \"ʑ\",\n",
      "    \"id\": \"Ahchypsy-Abkhaz-ɕ-ʑ\",\n",
      "    \"intermediate_steps\": [],\n",
      "    \"original_text\": \"ɕ ʑ → s z\",\n",
      "    \"to_sound\": \"z\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"Yunaga-2\",\n",
      "    \"index\": \"10.3.5.8.2\",\n",
      "    \"name\": \"Proto-Yunaga to Yunaga 2\",\n",
      "    \"source\": \"<i>thetha</i>, from Ozanne-Rivierre, Françoise (1992), “The Proto-Oceanic Consonantal System and the Languages of New Caledonia”. <i>Oceanic Linguistics</i> 31(2):191 – 207; and Ozanne-Rivierre, Françoise (1995), “Structural Changes in the Languages of Northern New Caledonia”. <i>Oceanic Linguistics</i> 34(1):44 – 72\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"Sekani\",\n",
      "    \"index\": \"29.1.1.1.18\",\n",
      "    \"name\": \"Proto-Athabaskan to Sekani\",\n",
      "    \"source\": \"<i>Whimemsz</i>, from Krauss, Michael and Victor Golla (1981), “Northern Athapaskan Languages”. <i>Handbook of North American Indians</i>, Vol. 6 (Subarctic), 67 – 85\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pickle, jsons\n",
    "from data_parsing_script import Rule, Branch\n",
    "with open('./data/rules.pkl', 'rb+') as rules_file:\n",
    "    rules = pickle.load(rules_file)\n",
    "with open('./data/branches.pkl', 'rb+') as branches_file:\n",
    "    branches = pickle.load(branches_file)\n",
    "\n",
    "print(f'{len(rules)} rules in {len(branches)} branches')\n",
    "print(jsons.dumps(rules[500], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(rules[4242], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(branches[123], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(branches[456], { 'indent': 4, 'ensure_ascii': False }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing more parsing issues\n",
    "\n",
    "I'm going to try to fix a few of the remaining parsing issues.\n",
    "\n",
    "(I also added some basic unit tests, since I don't want to break some previously-working parsing when fixing something else.)\n",
    "\n",
    "First, here's the \"all-or-nothing\" optional replacement issue, fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CxC', [], 'CaC'),\n",
       " ('xC', [], 'CaC'),\n",
       " ('Cx', [], 'CaC'),\n",
       " ('CxC', [], 'aC'),\n",
       " ('CxC', [], 'Ca'),\n",
       " ('x', [], 'CaC'),\n",
       " ('xC', [], 'aC'),\n",
       " ('xC', [], 'Ca'),\n",
       " ('Cx', [], 'aC'),\n",
       " ('Cx', [], 'Ca'),\n",
       " ('CxC', [], 'a'),\n",
       " ('x', [], 'aC'),\n",
       " ('x', [], 'Ca'),\n",
       " ('xC', [], 'a'),\n",
       " ('Cx', [], 'a'),\n",
       " ('x', [], 'a')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('(C)x(C) → (C)a(C)', '', '', '')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the nested brackets issue. This was more complex - it required completely rewriting how I was handling it. The final algorithm finds the deepest pair of curly braces, then replaces the bracketed string with the options inside the bracket and recurses on the resulting strings. This might help make that make sense:\n",
    "\n",
    "Step 1: `handle_brackets({e,w{æ,i}})`\n",
    "\n",
    "Step 2: `handle_brackets({e,wæ}), handle_brackets({e,wi})`\n",
    "\n",
    "Step 3: `handle_brackets(e), handle_brackets(wæ), handle_brackets(e), handle_brackets(wi)`\n",
    "\n",
    "Step 4: All 4 return because there are no more brackets in the string, the top-level function call puts the final strings into a set, and that set is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wæ', [], 'ø'), ('e', [], 'ø'), ('wi', [], 'ø')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('{e,w{æ,i}} → ø', '', '', '')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowel changes\n",
    "\n",
    "One of the things I want to look at in my analysis is how neighboring consonants affect vowel changes. This requires further parsing the existing sound changes, to find individual vowel changes and the consonants before and after those changing vowels.\n",
    "\n",
    "I put this in another function again: [vowel_changes.py](vowel_changes.py)\n",
    "\n",
    "I'll explain in words some of what it's doing:\n",
    "\n",
    "1. I'm excluding any rules that have more than one vowel sound, or diphthongs, in the \"from\" or \"to\". If there are multiple separate sounds, it'll be hard to ensure the correct pairs of vowels are matched between the \"from\" and \"to\" sounds; if there is a diphthong, it'll be hard to quantify *how* the sound changes in the way that I'm interested in.\n",
    "2. If the consonants around the vowel change with the vowel, I'm going to treat the original consonant as the \"neighbor\". This is kind of an arbitrary decision, but it makes more sense to me than any alternative I can think of.\n",
    "3. The consonants around the vowel are initially extracted from the from_sound and to_sound. If either is blank, it then checks if the environment contains information about the sound.\n",
    "4. Brackets and parentheses still had to be dealt with in the environment -- if a sound change's environment is \"_(l)d#\", that sound change should be represented twice, once with the next consonant being \"l\", and once with it being \"d\". I copied and adapted the code from the data parsing script to do this.\n",
    "5. Abbreviations get parsed, since environments use them so much - things like \"C\" representing consonants, \"F\" representing fricatives, etc., need to be represented in the data.\n",
    "\n",
    "Modifiers within square brackets were something that I looked into handling, but after looking at how many modifiers there were to handle, I decided to just ignore them for the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V[-nas]',\n",
       " 'V[+high +ATR]',\n",
       " 'F[+ voice]',\n",
       " 'V[-long]',\n",
       " 'C[+ affricate]',\n",
       " 'S[+voice]',\n",
       " 'V[+ rounded]',\n",
       " 'C[+pharyngeal]',\n",
       " 'u[+short]',\n",
       " 'V[-tone]',\n",
       " 'F[- same POA]',\n",
       " 'C[+dental]',\n",
       " 'C[+rhotic]',\n",
       " 'C[+dental +sibilant]',\n",
       " 'S[+voiced]',\n",
       " 'U[+closed]',\n",
       " 'C[+ voiced]',\n",
       " 'C[-nas]',\n",
       " 'N[+ same POA]',\n",
       " 'C[+dental -palatalized]',\n",
       " 'Z[+voiced]',\n",
       " 'C[+low]',\n",
       " 'K[-voice]',\n",
       " 'C[-low]',\n",
       " 'V[+nas -stress]',\n",
       " 'C[-back]',\n",
       " 'C[-high]',\n",
       " 'F[+voiced]',\n",
       " 'V[+ low]',\n",
       " 'V[-high]',\n",
       " 'ː[+falling tone]',\n",
       " 'C[-coronal]',\n",
       " 'C[+ dorsal]',\n",
       " 'U[+stress]',\n",
       " 'U[+open +posttonic]',\n",
       " 'S[- voice]',\n",
       " 'N[-labial]',\n",
       " 'O[+ labial]',\n",
       " 'V[-voiced]',\n",
       " 'C[-dental]',\n",
       " 'U[+tonic]',\n",
       " 'V[- stress]',\n",
       " 'U[+open]',\n",
       " 'ɡ[+ tone]',\n",
       " 'V[-front]',\n",
       " 'V[+round]',\n",
       " 'V[+ nasal]',\n",
       " 'U[+long -stress]',\n",
       " 'U[+u,a]',\n",
       " 'C[+ dental]',\n",
       " 'V[-back]',\n",
       " 'F[+palatal]',\n",
       " 'V[+nas]',\n",
       " 'V[- high]',\n",
       " 'N[-voiced]',\n",
       " 'C[+ labiovelar]',\n",
       " 'C[+coronal]',\n",
       " 'O[+voiced]',\n",
       " 'U[-long -stress]',\n",
       " 'V[+low]',\n",
       " 'C[-glottal]',\n",
       " 'i[-long]',\n",
       " 'k[+ fortis]',\n",
       " 'O[-voiced]',\n",
       " 'F[- voice]',\n",
       " 'C[+ uvular]',\n",
       " 'R[-labial]',\n",
       " '_[+intertonic]',\n",
       " 'C[+guttural]',\n",
       " 'C[-voice]',\n",
       " 'V[-low]',\n",
       " 'E[-stress]',\n",
       " 'V[+ high]',\n",
       " 'C[+ sibilant]',\n",
       " 'S[+velar]',\n",
       " 'C[+voice]',\n",
       " 'O[+ dental/alveolar]',\n",
       " 'C[+velar]',\n",
       " '}[+voiced]',\n",
       " 'ʷ[+uvular]',\n",
       " 'C[- voiced]',\n",
       " 'U[+ long + closed]',\n",
       " 'i[-long -stress]',\n",
       " 'J[+dorsal -voiced]',\n",
       " 'C[+palatal]',\n",
       " 'V[+ round]',\n",
       " '₁[+high]',\n",
       " 'V[+ nas]',\n",
       " 'S[-voiced]',\n",
       " 'V[+open-mid]',\n",
       " 'U[-stress]',\n",
       " 'C[+ alveolar]',\n",
       " 'V[+high]',\n",
       " 'C[-labial]',\n",
       " 'C[-palatalized +dental]',\n",
       " 'O[+labial]',\n",
       " 'U[+high pitch]',\n",
       " 'V[+close-mid]',\n",
       " 'O[+ same POA]',\n",
       " '}[+coronal]',\n",
       " 'C[+ dental/alveolar]',\n",
       " 'V[+ high tone]',\n",
       " 'X[+voiced]',\n",
       " 'C[+nasal]',\n",
       " 'U[-nas]',\n",
       " 'F[-palatal]',\n",
       " 'C[+sibilant]',\n",
       " 'C[+dorsal]',\n",
       " 'C[-nasal]',\n",
       " 'C[+labiodental]',\n",
       " 'C[- voice]',\n",
       " 'U[- stress]',\n",
       " 'U[- stressed]',\n",
       " 'C[+round]',\n",
       " 'V[+front]',\n",
       " 'C[+ fricative - voiced]',\n",
       " 'C[+voiced]',\n",
       " 'C[+high]',\n",
       " 'U[+e,i]',\n",
       " 'V[+ mid]',\n",
       " 'V[-stress]',\n",
       " 'V[- long]',\n",
       " 'C[+ voice]',\n",
       " 'J[+voiced]',\n",
       " 'V[+short]',\n",
       " 'P[-voice]',\n",
       " 'C[-palatal]',\n",
       " 't[+ fortis]',\n",
       " 'F[-voiced]',\n",
       " 'C[+alveolar]',\n",
       " 'E[-nas]',\n",
       " 'U[+open -initial -final]',\n",
       " 'C[-voiced]',\n",
       " 'F[+ sibilant]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from data_parsing_script import Rule\n",
    "\n",
    "rules: list[Rule] = pd.read_pickle('./data/rules.pkl')\n",
    "rules_df = pd.DataFrame.from_records([vars(rule) for rule in rules])\n",
    "\n",
    "modifiers = set()\n",
    "\n",
    "def get_modifiers(env: str):\n",
    "  modifier_matches = re.findall(r'.\\[[+-].+?\\]', env)\n",
    "  for match in modifier_matches:\n",
    "    modifiers.add(match)\n",
    "\n",
    "np.vectorize(get_modifiers)(rules_df['environment'])\n",
    "\n",
    "list(modifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...yeah, that's really too many. I *could* deal with this, but it would take forever, so I'm going to start by simply ignoring these and hoping I get enough data for the end result to be meaningful. If it seems like I have too little data, however, I'll work on dealing with modifiers.\n",
    "\n",
    "**[Continue to analysis →](analysis.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b2493083348fde2069711704c4dcbdb8e96ec3caa292c118280393371947b67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
