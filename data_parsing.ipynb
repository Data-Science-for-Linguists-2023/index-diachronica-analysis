{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n",
    "**[View the data parsing script!](data_parsing_script.py)**\n",
    "\n",
    "My goal with the data parsing is to fit each \"branch\" and sound change rule in the data into a predefined data format.\n",
    "\n",
    "How should I go about doing this? There are a few options. I want my end result to allow me to have a kind of connected graph between individual sounds, and I want to be able to see what rules and language branches the connections come from.\n",
    "\n",
    "Because of this, I think I want to have two different \"collections\" of objects:\n",
    "\n",
    "1. Rules\n",
    "2. Branches\n",
    "\n",
    "I'm going to opt to output these as JSON files, since I much prefer that format over XML for readability. I may also pickle them so that I can import them more easily when doing visualizations.\n",
    "\n",
    "Each object type will be its own class, so I can have a set of predefined fields on each.\n",
    "\n",
    "## Catching issues\n",
    "\n",
    "My first version of the data parsing script (2/21/23) worked somewhat well, but there were some that were parsed incorrectly. Here's a rundown of what was still not working:\n",
    "\n",
    "1. Sound changes with multiple correlated rules -- e.g. `z zː → j dʒː` -- were being parsed as single rules.\n",
    "2. Sounds grouped together -- e.g. in `{s3,ʒ} → ʃ / #_` -- were being parsed as one sound.\n",
    "3. Sounds like `S[+ voiced]` were being parsed as two separate sounds -- `S[+` and `voiced]` -- because I was naively splitting at all spaces.\n",
    "4. Some extra text was not being filtered out correctly, such as the quotation in `ɨ u → e {i,e} “(all */u/ affected, but conditions for when it became /i/ or /e/ are not known)”`.\n",
    "5. Rules like `rdʒ → {rdʒ,rdz(→ rz)}` that had optional steps were not parsed correctly at all.\n",
    "6. Optional modifiers to sounds, like `ts(ʼ)`, were parsed as one rule rather than two (`ts`, `tsʼ`.)\n",
    "\n",
    "**Have no idea what this means?** I don't blame you. I go into more detail in the [\"Parsing sound changes\" section](#parsing-sound-changes).\n",
    "\n",
    "There were almost certainly other issues, but these were the ones I noticed. Some of these were going to be harder to fix than others.\n",
    "\n",
    "There were some cases where making the parser handle a certain situation was not worth it, as the number of rules that would be handled by that was negligible, so I manually modified those rules so they would be parsed correctly. I also did this in cases where there was plain text like \"occasionally\". I made a new file `sid-tidy-with-edits.html` so the unedited version would still be accessible.\n",
    "\n",
    "There are also some rules where multiple end results are listed due to the source's author \"hedging\", so I edited those manually to consider both end results as their own rules.\n",
    "\n",
    "I also decided to make it so that anything within backticks is ignored when parsing but included in the 'original text' field of the rule. This lets me manually handle rules like `r → *L (some sort of lateral?) / occasionally` with extra stuff that I want to ignore, without losing that information.\n",
    "\n",
    "Another oddity is this fun one: `s → c& _ (the paper doesn’t explain what this represents)`. How am I supposed to parse this??? Who knows. I'm going to just manually add an environment separator and assume it's supposed to mean \"in any environment.\"\n",
    "\n",
    "I also realized there were some cases where there were simply typos in the data, such as `ŋ → {∅,n} #_ else` (which is missing the environment separator before `#_`.) I manually fixed those.\n",
    "\n",
    "Fortljus Ryggrad's *[Corrections, Clarifications, and Uncertainties of Index Diachronica](https://drive.google.com/file/d/1veWbeZhXUZjUtGZZezyvCvF6BA103wS8/view?usp=sharing)* helped me resolve some of the oddities I ran into when parsing as well.\n",
    "\n",
    "As I fixed some of the broken cases (+ others as I found them), I included them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', [], 'j'), ('zː', [], 'dʒː')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data_parsing_script as dps\n",
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('z zː → j dʒː')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', [], '[+ voice]')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('S → [+ voice]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j', [], 'i'), ('w', [], 'u')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('— j w → i u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V[- high - long]', [], '∅')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('V[- high - long] → ∅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ew', ['øj'], 'yj'), ('ew', [], 'yj')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('ew (→ øj) → yj', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s3', [], 'ʃ'), ('ʒ', [], 'ʃ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('{s3,ʒ} → ʃ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tʃʷʼ', [], 'fʼ'),\n",
       " ('tɕʼ', [], 'tsʼ'),\n",
       " ('dʒʷ', [], 'v'),\n",
       " ('dʑ', [], 'dz'),\n",
       " ('tʃʷ', [], 'f'),\n",
       " ('tɕ', [], 'ts')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('tʃʷ(ʼ) tɕ(ʼ) dʒʷ dʑ → f(ʼ) ts(ʼ) v dz', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rdʒ', [], 'rdʒ'), ('rdʒ', [], 'rdz')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in dps.parse_sound_change('rdʒ → {rdʒ,rdz}', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', [], 't'), ('ɡ', [], 'k')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('d ɡ → t k (may have been part of a more sweeping merger; Firespeaker calls it “lenis-fortis”)', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', [], '*L')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('r → *L `(some sort of lateral?)` / occasionally', '', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('æi', [], 'eː'),\n",
       " ('ei', [], 'eː'),\n",
       " ('ai', [], 'aː'),\n",
       " ('au', [], 'oː'),\n",
       " ('wɪ', [], 'weː'),\n",
       " ('wi', [], 'weː'),\n",
       " ('wu', [], 'woː'),\n",
       " ('wV', [], 'wVː'),\n",
       " ('i', [], 'eː'),\n",
       " ('u', [], 'oː'),\n",
       " ('V', [], 'Vː')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "dps.parse_rule_steps('{æ,e}i ai au w{ɪ,i} wu wV i u V → eː aː oː weː woː wVː eː oː Vː')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lːʀ', [], 'lː'), ('nːʀ', [], 'nː'), ('lʀ', [], 'lː'), ('nʀ', [], 'nː')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dps)\n",
    "\n",
    "[(rule.from_sound, rule.intermediate_steps, rule.to_sound) for rule in\n",
    "  dps.parse_sound_change('l(ː)ʀ n(ː)ʀ → lː nː / ”Vː_ (or all V_ ?)', '', '')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...AND IT ALL PARSES! Only took like 4 hours of running it over and over and fixing any errors that were hit!!\n",
    "\n",
    "However, as of now, there is still some data parsing stuff still to take care of:\n",
    "\n",
    "1. Rules with multiple optional things that are the same (e.g. `(C)(C)`) are only parsed as being all-or-nothing (one `(C)` is not possible). After fixing this, rules where `(:)` on both sides of the rule mean \"long becomes long, short becomes short\" still need to be handled correctly (e.g. `N(ː) k k(ː) N(ː)ɡ ɡ(ː) ɣ → ɲc(ː) c(ː) ɲɟ(ː) ɟ(ː) ʝ / _{i,j} `)\n",
    "2. Nested curly brackets are not handled correctly. (`{e,w{æ,i}}` is parsed as `['{e,wæ', '{e,wi}']`)\n",
    "3. I need to through everything and look for any more obvious errors. (Maybe sort individual sounds by length to find outliers?)\n",
    "\n",
    "I'm happy with the current state of things for the first progress report, though.\n",
    "\n",
    "## What the parser is doing\n",
    "\n",
    "1. It loops through each `<section>` tag on the page, each of which is a branch from a parent language to a daughter language (e.g. Proto-Germanic to Proto-Norse), and parses information about the branch. This is pretty simple.\n",
    "2. It then loops through each sound change listed in the section and parses THAT. This is where it gets messy.\n",
    "\n",
    "### Parsing sound changes\n",
    "\n",
    "Sound changes in the *Index* are in a (relatively...) standard format. The 'from' and 'to' sounds are separated by an arrow (with some intermediate steps sometimes), while the environment of the sound change is specified after a forward slash. The specifics of how environments are written aren't necessary to know for this, since I mostly just care about the sounds themselves.\n",
    "\n",
    "When parsing a sound change, first, any text contained in backticks is removed from the sound change text (as noted above), as is any `(?)`. Then, the environment is split off from the rest of the rule. (Often, rules are followed by some text in parentheses or double-quotes, so I include that in the environment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(sporadic)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "rule_string = 'd j → r ɭ (sporadic)'\n",
    "\n",
    "env_split = rule_string.split(\" / \", 1)\n",
    "\n",
    "environment = ''\n",
    "\n",
    "if len(env_split) > 1:\n",
    "    environment = env_split[1]\n",
    "else:\n",
    "    # If no environment, but rule ends with some text in parentheses or quotes, consider that the environment\n",
    "    parens_match = re.search(r'(.+) (\\(.+\\)|“.+”)$', rule_string)\n",
    "    if parens_match:\n",
    "        env_split[0] = parens_match.group(1)\n",
    "        environment = parens_match.group(2)\n",
    "\n",
    "environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the steps are split up and every sound is separated out. This is because I want single sound changes, like `a → o`, and a sound change like `a e → o i` is equivalent to `a → o` and `e → i` separately.\n",
    "\n",
    "This is the first place where things get pretty complex. First, I need to handle any 'optionals', the name I've given to stuff in parentheses in rules like `a(i) → ey`, which is equivalent to `a → ey` and `ai → ey` separately. Because there can be multiple in a single rule, I need to have every possible combination accounted for. I used `itertools`' `combinations()` function to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai {e,w{æ,i}} {we,ei} wɪ → ey ø y ʏ\n",
      "a {e,w{æ,i}} {we,ei} wɪ → ey ø y ʏ\n",
      "ai {e,w{æ,i}} {we,ei} ɪ → ey ø y ʏ\n",
      "a {e,w{æ,i}} {we,ei} ɪ → ey ø y ʏ\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "rule_string = 'a(i) {e,w{æ,i}} {we,ei} (w)ɪ → ey ø y ʏ'\n",
    "\n",
    "optionals = re.findall(r'(\\(.*?\\))', rule_string)\n",
    "if (optionals):\n",
    "    combinations = list(itertools.chain.from_iterable(itertools.combinations(optionals, l) for l in range(len(optionals) + 1)))\n",
    "    for combo in combinations:\n",
    "        combo_string = rule_string\n",
    "        for to_replace in combo:\n",
    "            combo_string = combo_string.replace(to_replace, '')\n",
    "        combo_string = combo_string.replace('(','').replace(')','')\n",
    "        print(combo_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, each of those are run through a `parse_rule_steps` function, which does a lot, including:\n",
    "\n",
    "1. Removing extraneous symbols\n",
    "2. Splitting the rules into steps\n",
    "3. Splitting the steps into each sound\n",
    "4. Making sure the number of sounds at each step are the same (so they can be correlated correctly)\n",
    "5. Splitting bracketed sounds into individual sounds, and generating rules for each combination of those individual sounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CaNs', 'CeNs', 'CiNs']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_brackets(sound: str) -> list[str]:\n",
    "    \"\"\"Handles bracketed sounds\"\"\"\n",
    "    sounds: list[str] = []\n",
    "    if bracket_matches := re.match(r'^(\\D+)?\\{(.*)\\}(\\D+)?$', sound):\n",
    "        # print(f'bracketed sound {sound}')\n",
    "        prefix = str(bracket_matches.group(1) or '')\n",
    "        split = bracket_matches.group(2).split(',')\n",
    "        suffix = str(bracket_matches.group(3) or '')\n",
    "        for sound in split:\n",
    "            sounds.append(prefix + sound + suffix)\n",
    "    else:\n",
    "        sounds.append(sound)\n",
    "    return sounds\n",
    "\n",
    "handle_brackets('C{a,e,i}Ns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, everything is output to JSON and pickle files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15865 rules in 702 branches\n",
      "{\n",
      "    \"environment\": \"\",\n",
      "    \"from_sound\": \"dʒ\",\n",
      "    \"id\": \"Eastern-Libyan-Arabic-dˤ-dʒ-q\",\n",
      "    \"intermediate_steps\": [],\n",
      "    \"original_text\": \"dˤ dʒ q → ðˤ ʒ ɡ\",\n",
      "    \"to_sound\": \"ʒ\"\n",
      "}\n",
      "{\n",
      "    \"environment\": \"\",\n",
      "    \"from_sound\": \"dɮ\",\n",
      "    \"id\": \"Proto-Circassian-ɬː-tɬː-tɬʼ-dɮ\",\n",
      "    \"intermediate_steps\": [],\n",
      "    \"original_text\": \"ɬ(ː) tɬ(ː) tɬʼ dɮ → ɕ(ː) tɕ(ː) tɕʼ tħ\",\n",
      "    \"to_sound\": \"tħ\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"Yunaga-2\",\n",
      "    \"index\": \"10.3.5.8.2\",\n",
      "    \"name\": \"Proto-Yunaga to Yunaga 2\",\n",
      "    \"source\": \"<i>thetha</i>, from Ozanne-Rivierre, Françoise (1992), “The Proto-Oceanic Consonantal System and the Languages of New Caledonia”. <i>Oceanic Linguistics</i> 31(2):191 – 207; and Ozanne-Rivierre, Françoise (1995), “Structural Changes in the Languages of Northern New Caledonia”. <i>Oceanic Linguistics</i> 34(1):44 – 72\"\n",
      "}\n",
      "{\n",
      "    \"id\": \"Sekani\",\n",
      "    \"index\": \"29.1.1.1.18\",\n",
      "    \"name\": \"Proto-Athabaskan to Sekani\",\n",
      "    \"source\": \"<i>Whimemsz</i>, from Krauss, Michael and Victor Golla (1981), “Northern Athapaskan Languages”. <i>Handbook of North American Indians</i>, Vol. 6 (Subarctic), 67 – 85\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pickle, jsons\n",
    "from data_parsing_script import Rule, Branch\n",
    "with open('./data/rules.pkl', 'rb+') as rules_file:\n",
    "    rules = pickle.load(rules_file)\n",
    "with open('./data/branches.pkl', 'rb+') as branches_file:\n",
    "    branches = pickle.load(branches_file)\n",
    "\n",
    "print(f'{len(rules)} rules in {len(branches)} branches')\n",
    "print(jsons.dumps(rules[500], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(rules[4242], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(branches[123], { 'indent': 4, 'ensure_ascii': False }))\n",
    "print(jsons.dumps(branches[456], { 'indent': 4, 'ensure_ascii': False }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b2493083348fde2069711704c4dcbdb8e96ec3caa292c118280393371947b67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
